services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: ${VLLM_CONTAINER_NAME:-vllm-qwen3-coder-30b}
    restart: unless-stopped
    shm_size: "32gb"
    environment:
      HF_TOKEN: ${HF_TOKEN:-}
      VLLM_USE_V1_API: "1"
      VLLM_WORKER_USE_NATIVE_SCHEDULER: "1"
    command:
      - "--model"
      - "${MODEL_PATH}"
      - "--tokenizer"
      - "${TOKENIZER_PATH:-${MODEL_PATH}}"
      - "--max-model-len"
      - "${MAX_MODEL_LEN:-32768}"
      - "--tensor-parallel-size"
      - "${TENSOR_PARALLEL:-1}"
      - "--gpu-memory-utilization"
      - "${GPU_MEMORY_UTILIZATION:-0.9}"
      - "--max-num-seqs"
      - "${MAX_NUM_SEQS:-256}"
      - "--dtype"
      - "${DTYPE:-auto}"
      - "--enforce-eager"
      - "${ENFORCE_EAGER:-True}"
      - "--trust-remote-code"
      - "--api-key"
      - "${VLLM_API_KEY:-local-dev}"
    ports:
      - "${VLLM_PORT:-8004}:8000"
    volumes:
      - ${HOST_MODELS_DIR:-/home/shan/models}:${CONTAINER_MODELS_DIR:-/models}:ro
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
